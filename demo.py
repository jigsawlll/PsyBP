# app_cli_original_functions.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  åŠŸèƒ½ï¼šä¿ç•™åŸæ–‡ä»¶æ‰€æœ‰å‡½æ•°ç»“æ„ï¼Œç§»é™¤ Flask/DBï¼Œæ”¹é€ ä¸ºå‘½ä»¤è¡Œåº”ç”¨ã€‚
#  è¯´æ˜ï¼šè¿è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€åº“ï¼špip install transformers torch
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import glob
import threading
import torch
from datetime import datetime
from threading import Thread
from transformers import (AutoTokenizer, AutoModelForCausalLM,
                          TextIteratorStreamer, BitsAndBytesConfig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  0. å…¨å±€å¸¸é‡ (ä¿ç•™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BASE_USER_DIR = os.path.join(BASE_DIR, "user_data")  # æ¯ä¸ªç”¨æˆ·ï¼šhistory / portrait
DEFAULT_USER_ID = "cli_user"  # ä¸ºå‘½ä»¤è¡Œç•Œé¢è®¾ç½®ä¸€ä¸ªé»˜è®¤ç”¨æˆ·ID

os.makedirs(BASE_USER_DIR, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  1. ç”¨æˆ·ç›®å½•å·¥å…· (ä¿ç•™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_user_dirs(user_id: str):
    """ä¸ºæŒ‡å®š user_id åˆ›å»º user_data/{uid}/history portrait ç›®å½•"""
    root = os.path.join(BASE_USER_DIR, user_id)
    os.makedirs(os.path.join(root, "history"), exist_ok=True)
    os.makedirs(os.path.join(root, "portrait"), exist_ok=True)


def list_history_files(user_id: str):
    p = os.path.join(BASE_USER_DIR, user_id, "history")
    return sorted(os.path.basename(f) for f in glob.glob(os.path.join(p, "*.txt")))


def list_portrait_files(user_id: str):
    p = os.path.join(BASE_USER_DIR, user_id, "portrait")
    return sorted(os.path.basename(f) for f in glob.glob(os.path.join(p, "*.txt")))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  2. æ¨¡å‹åŠ è½½ (ä¿ç•™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_PATH = r"E:\model\PsyBPLLM"  # â˜… æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹
bnb_cfg = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
)


def _load_model():
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        trust_remote_code=True,
        device_map="auto",
        torch_dtype=torch.bfloat16,
        quantization_config=bnb_cfg
    )
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_PATH,
        trust_remote_code=True
    )
    streamer = TextIteratorStreamer(
        tokenizer=tokenizer,
        skip_prompt=True,
        skip_special_tokens=True
    )
    return model, tokenizer, streamer


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  3. å¯¹è¯å†å²å®¹å™¨ (ä¿ç•™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆå’Œå¿ƒç†ä¸“å®¶ï¼Œå¹¶ä¸”ç²¾é€šä»æ–‡å­—ä¸­æå–æ¥è®¿è€…çš„åŸºæœ¬ä¿¡æ¯å¹¶èƒ½åŸºäºæ¥è®¿è€…çš„åŸºæœ¬ä¿¡æ¯ä¸æ‚£è€…è¿›è¡Œå¿ƒç†å’¨è¯¢."
)
USER_CHAT_HISTORIES = {}  # user_id -> list[dict]
_history_lock = threading.Lock()


def get_user_chat_history(uid: str):
    """è·å–æˆ–åˆå§‹åŒ–æŒ‡å®šç”¨æˆ·çš„å¯¹è¯å†å²"""
    if uid not in USER_CHAT_HISTORIES:
        with _history_lock:
            if uid not in USER_CHAT_HISTORIES:
                USER_CHAT_HISTORIES[uid] = [
                    {"role": "system", "content": DEFAULT_SYSTEM_PROMPT}
                ]
    return USER_CHAT_HISTORIES[uid]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  4. ä¿å­˜å¯¹è¯ & ç”Ÿæˆ / æ³¨å…¥ç”»åƒ (ä¿ç•™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _timestamp():
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def _save_conversation(uid: str, history: list):
    """å°†å†…å­˜ä¸­çš„å¯¹è¯å†å²ä¿å­˜åˆ°æ–‡ä»¶"""
    if not uid: return "é”™è¯¯ï¼šæ— æ³•åœ¨æœªæŒ‡å®šç”¨æˆ·çš„æƒ…å†µä¸‹ä¿å­˜ï¼"

    # å°† list[dict] æ ¼å¼çš„å†å²è®°å½•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    conv_str = ""
    for msg in history:
        if msg['role'] != 'system':  # é€šå¸¸ä¸ä¿å­˜ system prompt
            conv_str += f"{msg['role'].capitalize()}: {msg['content']}\n\n"

    if not conv_str.strip():
        return "å¯¹è¯ä¸ºç©ºï¼Œæ— éœ€ä¿å­˜ã€‚"

    hist_dir = os.path.join(BASE_USER_DIR, uid, "history")
    os.makedirs(hist_dir, exist_ok=True)
    fname = f"history_{_timestamp()}.txt"
    try:
        with open(os.path.join(hist_dir, fname), "w", encoding="utf-8") as f:
            f.write(conv_str)
        return f"âœ… å¯¹è¯å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{fname}"
    except Exception as e:
        return f"ä¿å­˜å¤±è´¥ï¼š{e}"


def _generate_portrait_from_file(uid: str, file_name: str, model, tokenizer):
    """ä»æŒ‡å®šçš„å†å²æ–‡ä»¶ç”Ÿæˆç”¨æˆ·ç”»åƒ"""
    if not uid or not file_name:
        return "é”™è¯¯ï¼šæœªæä¾›æœ‰æ•ˆå¯¹è¯æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆç”¨æˆ·ç”»åƒï¼"
    path = os.path.join(BASE_USER_DIR, uid, "history", file_name)
    if not os.path.isfile(path):
        return f"é”™è¯¯ï¼šé€‰å®šçš„å¯¹è¯æ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„: {path}"

    with open(path, encoding="utf-8") as f:
        conv = f.read()

    messages = [
        {"role": "system",
         "content": (
             "ä½ æ˜¯ä¸€åä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆå’Œæ–‡å­—åˆ†æä¸“å®¶ã€‚"
             "ä¸‹é¢ user ä¼šç»™ä½ ä¸€æ®µå®Œæ•´å¯¹è¯ï¼Œè¯·ä½ **ä»…**æŒ‰ä»¥ä¸‹ä¹ä¸ªè¦ç‚¹æå–ä¿¡æ¯ï¼Œ"
             "ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–ç”¨æˆ·ç”»åƒï¼ˆç”¨ Markdown åˆ—è¡¨å‡å¯ï¼‰ã€‚"
             "ä¸å¾—ç»­å†™å¯¹è¯ã€ä¸å¾—æ·»åŠ æ— å…³å†…å®¹ï¼Œè®°å½•ä¸­æœªæåˆ°çš„å†™â€œæœªæåŠâ€ï¼š\n"
             "â‘  åŸºæœ¬ä¿¡æ¯(å¹´é¾„ï¼Œæ€§åˆ«ï¼ŒèŒä¸šï¼Œç”Ÿæ´»çŠ¶å†µ)\n"
             "â‘¡ æƒ…ç»ªçŠ¶æ€\nâ‘¢ å¿ƒç†éœ€æ±‚ä¸ç›®æ ‡\nâ‘£ åº”å¯¹æœºåˆ¶\nâ‘¤ è®¤çŸ¥æ¨¡å¼\n"
             "â‘¥ ç¤¾ä¼šæ”¯æŒä¸äººé™…å…³ç³»\nâ‘¦ ç”Ÿæ´»è´¨é‡\nâ‘§ è®¤çŸ¥ä¸æƒ…æ„Ÿå€¾å‘\nâ‘¨ å’¨è¯¢ä¸­ååº”"
         )},
        {"role": "user", "content": conv}
    ]
    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outs = model.generate(**inputs, max_new_tokens=2048, do_sample=False)
    resp = tokenizer.decode(outs[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True)

    # ä¿å­˜ç”»åƒæ–‡ä»¶
    por_dir = os.path.join(BASE_USER_DIR, uid, "portrait")
    os.makedirs(por_dir, exist_ok=True)
    fname = f"ç”¨æˆ·ç”»åƒ_{_timestamp()}.txt"
    with open(os.path.join(por_dir, fname), "w", encoding="utf-8") as f:
        f.write(resp)

    print("\n" + "=" * 20 + " ç”¨æˆ·ç”»åƒå·²ç”Ÿæˆ " + "=" * 20)
    print(resp)
    print("=" * 58 + "\n")
    return f"âœ… ç”¨æˆ·ç”»åƒå·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°æ–‡ä»¶ï¼š{fname}"


def _inject_portrait(uid: str, portrait_file: str):
    """ä»æŒ‡å®šçš„ç”»åƒæ–‡ä»¶è¯»å–å†…å®¹å¹¶æ³¨å…¥åˆ°å½“å‰å¯¹è¯çš„ system prompt"""
    if not uid or not portrait_file:
        return "é”™è¯¯ï¼šæœªé€‰æ‹©ç”»åƒæ–‡ä»¶ï¼"
    p_path = os.path.join(BASE_USER_DIR, uid, "portrait", portrait_file)
    if not os.path.isfile(p_path):
        return f"é”™è¯¯ï¼šç”»åƒæ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„: {p_path}"

    with open(p_path, encoding="utf-8") as f:
        content = f.read()

    hist = get_user_chat_history(uid)
    # ç§»é™¤æ—§çš„ç”»åƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œä¿ç•™æœ€åŸºç¡€çš„ system prompt
    base_sys = hist[0]["content"].split("### ç”¨æˆ·ç”»åƒï¼ˆä¾›å‚è€ƒ", 1)[0].rstrip()

    # æ³¨å…¥æ–°çš„ç”»åƒ
    hist[0]["content"] = base_sys + "\n### ç”¨æˆ·ç”»åƒï¼ˆä¾›å‚è€ƒï¼Œè¯·å‹¿ç›´æ¥å±•ç¤ºï¼‰\n" + content.strip()
    return f"âœ… å·²å°† {portrait_file} çš„å†…å®¹æ³¨å…¥åˆ°å½“å‰å¯¹è¯ä¸­ã€‚"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  5. ä¸»ç¨‹åº & å‘½ä»¤è¡Œäº¤äº’
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    """ä¸»äº¤äº’å¾ªç¯"""
    print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™ â€¦")
    model, tokenizer, streamer = _load_model()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•")

    # ä¸ºå½“å‰å‘½ä»¤è¡Œä¼šè¯åˆå§‹åŒ–ç”¨æˆ·ç›®å½•å’Œå¯¹è¯å†å²
    create_user_dirs(DEFAULT_USER_ID)
    history = get_user_chat_history(DEFAULT_USER_ID)

    print("\n" + "=" * 60)
    print("æ¬¢è¿ä½¿ç”¨å‘½ä»¤è¡Œå¿ƒç†å’¨è¯¢åŠ©æ‰‹ã€‚")
    print("æ”¯æŒçš„å‘½ä»¤:")
    print("  /save             - ä¿å­˜å½“å‰å¯¹è¯åˆ° history ç›®å½•")
    print("  /list history     - åˆ—å‡ºå·²ä¿å­˜çš„å¯¹è¯æ–‡ä»¶")
    print("  /list portraits   - åˆ—å‡ºå·²ç”Ÿæˆçš„ç”»åƒæ–‡ä»¶")
    print("  /gen portrait     - ï¼ˆè·Ÿæ®æç¤ºï¼‰ä»æŒ‡å®šå¯¹è¯æ–‡ä»¶ç”Ÿæˆç”»åƒ")
    print("  /inject portrait  - ï¼ˆè·Ÿæ®æç¤ºï¼‰å°†æŒ‡å®šç”»åƒæ³¨å…¥å½“å‰å¯¹è¯")
    print("  /reset            - é‡ç½®å½“å‰å¯¹è¯å†å²")
    print("  /quit             - é€€å‡ºç¨‹åº")
    print("=" * 60 + "\n")

    while True:
        try:
            user_input = input("\nYou: ")
            cmd = user_input.lower()

            if cmd == "/quit":
                print("å†è§ï¼")
                break

            elif cmd == "/reset":
                USER_CHAT_HISTORIES.pop(DEFAULT_USER_ID, None)
                history = get_user_chat_history(DEFAULT_USER_ID)
                print("\n[ç³»ç»Ÿ] å¯¹è¯å·²é‡ç½®ã€‚")
                continue

            elif cmd == "/save":
                status = _save_conversation(DEFAULT_USER_ID, history)
                print(f"\n[ç³»ç»Ÿ] {status}")
                continue

            elif cmd == "/list history":
                files = list_history_files(DEFAULT_USER_ID)
                print("\n[ç³»ç»Ÿ] å·²ä¿å­˜çš„å¯¹è¯æ–‡ä»¶:")
                if not files: print("  - æ— ")
                for f in files: print(f"  - {f}")
                continue

            elif cmd == "/list portraits":
                files = list_portrait_files(DEFAULT_USER_ID)
                print("\n[ç³»ç»Ÿ] å·²ç”Ÿæˆçš„ç”»åƒæ–‡ä»¶:")
                if not files: print("  - æ— ")
                for f in files: print(f"  - {f}")
                continue

            elif cmd == "/gen portrait":
                files = list_history_files(DEFAULT_USER_ID)
                if not files:
                    print("\n[ç³»ç»Ÿ] æ²¡æœ‰ä»»ä½•å·²ä¿å­˜çš„å¯¹è¯æ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨ /save ä¿å­˜ã€‚")
                    continue
                fname = input(f"[ç³»ç»Ÿ] è¯·è¾“å…¥è¦ç”¨äºç”Ÿæˆç”»åƒçš„å¯¹è¯æ–‡ä»¶å (ä¾‹å¦‚: {files[-1]}): ")
                status = _generate_portrait_from_file(DEFAULT_USER_ID, fname.strip(), model, tokenizer)
                print(f"\n[ç³»ç»Ÿ] {status}")
                continue

            elif cmd == "/inject portrait":
                files = list_portrait_files(DEFAULT_USER_ID)
                if not files:
                    print("\n[ç³»ç»Ÿ] æ²¡æœ‰ä»»ä½•å·²ç”Ÿæˆçš„ç”»åƒæ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨ /gen portrait ç”Ÿæˆã€‚")
                    continue
                fname = input(f"[ç³»ç»Ÿ] è¯·è¾“å…¥è¦æ³¨å…¥çš„ç”»åƒæ–‡ä»¶å (ä¾‹å¦‚: {files[-1]}): ")
                status = _inject_portrait(DEFAULT_USER_ID, fname.strip())
                print(f"\n[ç³»ç»Ÿ] {status}")
                continue

            # --- å¦‚æœä¸æ˜¯å‘½ä»¤ï¼Œåˆ™è¿›è¡Œå¯¹è¯ ---
            history.append({"role": "user", "content": user_input})
            prompt = tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)
            inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

            generation_kwargs = dict(
                **inputs, streamer=streamer, max_new_tokens=1024,
                do_sample=True, top_p=0.95, temperature=0.8
            )
            Thread(target=model.generate, kwargs=generation_kwargs).start()

            print("\nAssistant: ", end="", flush=True)
            assistant_response = ""
            for chunk in streamer:
                print(chunk, end="", flush=True)
                assistant_response += chunk

            history.append({"role": "assistant", "content": assistant_response})

        except KeyboardInterrupt:
            print("\nå†è§ï¼")
            break
        except Exception as e:
            print(f"\nå‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            break


if __name__ == "__main__":
    main()